import torch
import pandas as pd
from collections import defaultdict

# ----------- æ¨¡æ“¬åƒæ•¸ -------------
must_lose_rate = 0.07        # è¨­å®šå¿…è¼¸ç‡ (0.01 = 1%)
batch_size = 10_000_000        # æ¯æ‰¹æ¨¡æ“¬æ•¸
max_total = 100_000_000_000  # æœ€å¤šæ¨¡æ“¬æ•¸ï¼š1 å…†
rtp_tolerance = 0.001          # RTP èª¤å·®å®¹è¨±ç¯„åœ
success_streak_required = 10   # é€£çºŒå¹¾æ‰¹è½åœ¨ç¯„åœå…§å°±æå‰åœæ­¢

# ----------- è³ ç‡èˆ‡æ¬Šé‡è³‡æ–™ï¼ˆRTP 100% è¨­å®šï¼‰-------------
multipliers = [
    0, 0, 0, 0,
    10000, 10000, 8000, 6000, 5000, 4000, 4000, 3000,
    2000, 2000, 2000, 1500, 1000, 1000, 800, 600, 500,
    400, 400, 300, 200, 200, 200, 150, 100, 100, 100,
    80, 75, 60, 50, 50, 40, 40, 30, 25, 20, 20, 20,
    15, 10, 10, 8, 6, 5, 4, 4, 3, 2, 2, 1
]
weights = [
    462217, 136615, 56923, 27323,
    1, 2, 2, 2, 2, 2, 2, 4,
    1, 1, 2, 5, 4, 4, 10, 10, 20,
    15, 15, 40, 10, 13, 20, 50, 15, 30, 80,
    150, 150, 200, 250, 250, 300, 500, 650, 1000, 300,
    810, 1000, 2200, 1500, 1300, 2900, 3000, 8500, 4500, 7200,
    14000, 51000, 74500, 140400
]

# ----------- åˆå§‹åŒ–å¼µé‡èˆ‡ç†è«–è¡¨ -------------
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
multipliers_tensor = torch.tensor(multipliers, dtype=torch.float32, device=device)  # MPS é™åˆ¶åªèƒ½ç”¨ float32
weights_tensor = torch.tensor(weights, dtype=torch.float32, device=device)
probabilities = weights_tensor / weights_tensor.sum()

df_theoretical = pd.DataFrame({
    "å€æ•¸": multipliers,
    "ç†è«–æ¬Šé‡": weights
})
df_theoretical["ç†è«–å‡ºç¾ä½”æ¯” (%)"] = df_theoretical["ç†è«–æ¬Šé‡"] / weights_tensor.sum().item() * 100 * (1-must_lose_rate)
df_theoretical = df_theoretical.groupby("å€æ•¸", as_index=False).sum().sort_values(by="å€æ•¸", ascending=False)

# ----------- æ¨¡æ“¬ä¸»è¿´åœˆ (GPU é‹ç®— + CPU ç²¾åº¦ç´¯åŠ ) -------------
total_return = torch.tensor(0.0, dtype=torch.float64)  # CPU ç´¯åŠ ç”¨ float64
total_wins = torch.tensor(0.0, dtype=torch.float64)    # CPU ç´¯åŠ ç”¨ float64
count_dict = defaultdict(int)
num_simulated = torch.tensor(0.0, dtype=torch.float64)

rtp_target = 1.0 - must_lose_rate
rtp_success_streak = 0
max_batches = max_total // batch_size

for i in range(max_batches):
    samples = torch.multinomial(probabilities, batch_size, replacement=True)
    drawn = multipliers_tensor[samples]

    # å¼·åˆ¶ä¸ä¸­ç
    if must_lose_rate > 0:
        mask = (torch.rand(batch_size, device=device) < must_lose_rate) & (drawn > 0)
        drawn[mask] = 0.0

    # å…ˆåœ¨ GPU sumï¼Œå†è½‰ CPU float64 ç´¯åŠ 
    total_return += drawn.sum().cpu().to(torch.float64)
    total_wins += (drawn > 0).sum().cpu().to(torch.float64)
    num_simulated += batch_size

    # çµ±è¨ˆæ¯å€‹å€æ•¸å‡ºç¾æ¬¡æ•¸ï¼ˆCPU è™•ç†ï¼‰
    for m in drawn.cpu().numpy():
        count_dict[float(m)] += 1

    # è¨ˆç®—ç´¯ç© RTPï¼ˆfloat64 ç²¾åº¦ï¼‰
    current_rtp = (total_return / num_simulated).item()
    if rtp_target - rtp_tolerance <= current_rtp <= rtp_target + rtp_tolerance:
        rtp_success_streak += 1
    else:
        rtp_success_streak = 0

    print(f"ç¬¬ {i+1} æ‰¹ï½œæ¨¡æ“¬æ•¸: {int(num_simulated):,}ï½œRTP: {current_rtp:.5f}ï½œä¸­çç‡: {(total_wins / num_simulated)*100:.2f}%ï½œç©©å®šé€£çºŒæ‰¹æ•¸: {rtp_success_streak}")

    if rtp_success_streak >= success_streak_required:
        print("âœ… æå‰å®Œæˆï¼šå·²é”é€£çºŒç©©å®šæ¢ä»¶")
        break

# ----------- åŒ¯å‡ºçµæœ -------------
df_actual = pd.DataFrame([
    {"å€æ•¸": k, "å¯¦éš›å‡ºç¾æ¬¡æ•¸": v, "å¯¦éš›å‡ºç¾ä½”æ¯” (%)": (v / num_simulated.item()) * 100}
    for k, v in count_dict.items()
])
df_actual = df_actual.sort_values(by="å€æ•¸", ascending=False)

df_result = pd.merge(df_theoretical, df_actual, on="å€æ•¸", how="outer").fillna(0)
df_result = df_result.sort_values(by="å€æ•¸", ascending=False)

df_result.to_excel("æ¨¡æ“¬çµæœ_è³ ç‡çµ±è¨ˆ.xlsx", index=False)

print("\nâœ… Excel å·²åŒ¯å‡ºï¼šæ¨¡æ“¬çµæœ_è³ ç‡çµ±è¨ˆ.xlsx")
print(f"ğŸ¯ æ¨¡æ“¬ç¸½æ¬¡æ•¸ï¼š{int(num_simulated):,}")
print(f"ğŸ“ˆ æœ€çµ‚ RTPï¼š{(total_return / num_simulated).item():.5f}")
print(f"ğŸ¥‡ ä¸­çç‡ï¼š{(total_wins / num_simulated).item() * 100:.2f}%")
